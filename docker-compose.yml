version: '3'
services:
  postgres:
    build:
      context: ./docker/docker-postgres/
      dockerfile: Dockerfile
    image: postgres
    container_name: postgres
    restart: on-failure
    networks:
      - default_net
    environment:
      - POSTGRES_USERS=airflow:airflow|metabase:metabase
      - POSTGRES_DATABASES=airflow:airflow|metabase:metabase
    ports:
      - 5433:5432
    healthcheck:
      test: [ "CMD", "pg_isready" ]
      interval: 60s
      timeout: 20s
      retries: 3

  # Airflow LocalExecutor
  airflow-webserver:
    build:
      context: ./docker/docker-airflow/
      dockerfile: Dockerfile
    image: airflow-spark
    container_name: airflow-webserver
    restart: on-failure
    networks:
      - default_net
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - LOAD_EX=n
      - EXECUTOR=Local
    volumes:
      - ./dags:/root/airflow/dags
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources
    ports:
      - 8080:8080
    command: webserver
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "[ -f /root/airflow/airflow-webserver.pid ]"
        ]
      interval: 30s
      timeout: 30s
      retries: 3

  # Spark with 2 worker
  spark:
    image: spark
    build:
      context: ./docker/docker-spark/
      dockerfile: Dockerfile
    user: root
    hostname: spark
    restart: on-failure
    container_name: spark-master
    networks:
      - default_net
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources
    ports:
      - 8181:8181
      - 7077:7077

  spark-worker-1:
    image: spark
    build:
      context: ./docker/docker-spark/
      dockerfile: Dockerfile
    user: root
    restart: on-failure
    container_name: spark-worker-1
    networks:
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources

  spark-worker-2:
    image: spark
    build:
      context: ./docker/docker-spark/
      dockerfile: Dockerfile
    user: root
    restart: on-failure
    container_name: spark-worker-2
    networks:
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/app:/usr/local/spark/app
      - ./spark/resources:/usr/local/spark/resources

  # Jupyter notebook
  jupyter-spark:
    image: jupyter/pyspark-notebook:spark-3.4.0
    restart: on-failure
    container_name: jupyter-spark
    networks:
      - default_net
    ports:
      - 8888:8888
      - 4040-4080:4040-4080
    volumes:
      - ./notebooks:/home/jovyan/work/notebooks/
      - ./spark/resources/data:/home/jovyan/work/data/
      - ./spark/resources/jars:/home/jovyan/work/jars/

  metabase-app:
    image: metabase/metabase
    restart: on-failure
    ports:
      - 3001:3000
    environment:
      - MB_DB_TYPE=postgres
      - MB_DB_DBNAME=metabase
      - MB_DB_PORT=5432
      - MB_DB_USER=metabase
      - MB_DB_PASS=metabase
      - MB_DB_HOST=postgres
    depends_on:
      - postgres
    networks:
      - default_net

networks:
  default_net:
